---
title: 决策树
date: 2018-11-18 16:47:43
categories:
- 机器学习
tags:
---
ID3算法，C4.5算法，CART算法

 

优点:计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。

缺点:可能会产生过度匹配问题。

适用数据类型:数值型和标称型。

 

 

1.收集数据:可以使用任何方法。

2.准备数据:树构造算法只适用于标称型数据，因此数值型数据必须离散化。

3.分析数据:可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。

4.训练算法:构造树的数据结构。

5.测试算法:使用经验树计算错误率。

6.使用算法:此步骤可以适用于任何监督学习算法发，而使用决策树可以更好地理解数据的内在含义。

 

划分数据集的大原则是：将无需的数据变得更加有序。

 

组织杂乱无章数据的一种方法就是使用信息论度量信息。

在划分数据集之前之后发生的变化称为信息增益。集合信息的度量方式称为香农熵或者简称为熵。

熵定义为信息的期望值。如果待分类的事务可能划分在多个分类之中，则

 

所有类别所有可能值包含的信息期望值，



 

另一种度量集合无序程度的方法是基尼不纯度

从一个数据集中随机选取子项，度量其被错误分类到其他分组里的概率。

 

决策树分类器就像带有终止块的流程图，终止块表示分类结果。开始处理数据集时，我们首先需要测量集合中数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。ID3算法可以用于划分标称型数据集。构建决策树时，我们通常采用递归的方法将数据集转化为决策树。