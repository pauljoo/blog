---
title: 机器学习-概览
date: 2018-11-18 16:47:26
categories:
- 机器学习
tags:
---

## 根据训练时监督的量和类型进行分类

### 监督学习
之所以称为监督学习，是因为这类算法必须知道预测什么，即目标变量的分类信息。(分类、回归)

* K近邻算法
* 线性回归
* 逻辑回归
* 支持向量机
* 决策树和随机森林
* 神经网络
### 无监督学习
此时数据没有类别信息，也不会给定目标值。(聚类)

* 聚类
    - K均值
    - 层次聚类分析（HCA）
    - 期望最大值
* 可视化和降维
    - 主成分分析（PCA）
    - 核主成分分析
    - 局部线性嵌入（LLE）
    - t-分布领域嵌入算法（t-SNE）
* 关联性规则学习
    - Apriori算法
    - Eclat算法

### 半监督学习
一些算法可以处理部分带标签的训练数据，通常是大量不带标签数据加上小部分带标签数据。

* 深度信念网络
* 受限玻尔兹曼机（RBM）
### 强化学习
学习系统在这里被称为（agent），可以对环境进行观察，选择和执行动作，获得奖励（惩罚）。然后它必须自己学习哪个是最佳方法（策略），
以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动。

## 根据是否能从导入的数据流进行持续学习
### 在线学习
在线学习中，使用数据实例持续地进行训练，可以一次一个或一次几个实例（小批量），且自动对改变做出调整。

在线学习系统的一个重要参数是，它们可以多快地适应数据的改变：这被称为学习速率。

在线学习的挑战之一是，如果坏数据被用来进行训练，系统的性能就会逐渐下滑。
例如，坏数据可能来自失灵的传感器或机器人，或某人向搜索引擎传入垃圾信息以提高搜索排名。要减小这种风险，你需要密集监测，
如果检测到性能下降，要快速关闭（或是滚回到一个之前的状态） 。
你可能还要监测输入数据，对反常数据做出反应（比如，使用异常检测算法） 。

### 批量学习
在批量学习中，系统不能进行持续学习：必须用所有可用数据进行训练。首先是进行训练，然后部署在生产环境且停止学习，
它只是使用已经学到的策略。这称为离线学习。

## 如何进行归纳推广
大多机器学习任务是关于预测的。这意味着给定一定数量的训练样本，系统需要能推广到之前没见到过的样本。
对训练数据集有很好的性能还不够，真正的目标是对新实例预测的性能。

### 基于实例学习
系统先用记忆学习案例，然后使用相似度测量推广到新的例子

如果用这种方法做一个垃圾邮件检测器，只需标记所有和用户标记的垃圾邮件相同的邮件 。
一个（简单的） 相似度测量方法是统计两封邮件包含的相同单词的数量。如果一封邮件含有许多垃圾邮件中的词，就会被标记为垃圾邮件。

### 基于模型学习
另一种从样本集进行归纳的方法是建立这些样本的模型，然后使用这个模型进行预测。这称作基于模型学习。

首先，选一个线性模型。
接下来，就是线性回归算法，你用训练样本训练算法，算法找到使线性模型最拟合数据的参数。这称作模型训练。
最后，可以准备运行模型进行预测了。

## 机器学习算法应用程序开发步骤：

1.收集数据
2.准备输入数据
3.分析输入数据
4.训练算法(无监督学习除外，由于不存在目标变量，故而也不需要训练算法)
5.测试算法
6.使用算法

## 机器学习的主要挑战

### 训练数据量不足
需要大量数据，才能让多数机器学习算法正常工作。即便对于非常简单的问题，一般也需要数千的样本，
对于复杂的问题，比如图像或语音识别，你可能需要数百万的样本

### 没有代表性的训练数据
为了更好地进行归纳推广，让训练数据对新数据具有代表性是非常重要的。无论你用的是基于实例学习或基于模型学习，这点都很重要。
如果样本太小，就会有样本噪声（即，会有一定概率包含没有代表性的数据），
但是即使是非常大的样本也可能没有代表性，如果取样方法错误的话。这叫做样本偏差。

### 低质量数据
如果训练集中的错误、异常值和噪声（错误测量引入的） 太多，系统检测出潜在规律的难度就会变大，性能就会降低。

### 不相关的特征
进来的是垃圾，出去的也是垃圾。你的系统只有在训练数据包含足够相关特征、非相关特征不多的情况下，才能进行学习。
机器学习项目成功的关键之一是用好的特征进行训练。

### 过拟合训练数据
模型在训练数据上表现很好，但是推广效果不好。
复杂的模型，比如深度神经网络，可以检测数据中的细微规律，但是如果训练集有噪声，或
者训练集太小（太小会引入样本噪声） ，模型就会去检测噪声本身的规律。很明显，这些规
律不能推广到新实例。

### 欠拟合训练数据
当你的模型过于简单时就会发生。例如，生活满意度的线性模型倾向于欠拟合；现实要比这个模型复杂的多，所以预测很难准确，
即使在训练样本上也很难准确。